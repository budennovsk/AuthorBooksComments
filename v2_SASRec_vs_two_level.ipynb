{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1N9ELVwC7Vf72jlYlO8wDBi3-wQ_DRImu",
      "authorship_tag": "ABX9TyMWeNPklz/HDtjXuLfzATld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/budennovsk/AuthorBooksComments/blob/master/v2_SASRec_vs_two_level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install implicit catboost rectools[lightfm] replay-rec==0.21.2rc0 #replay-rec\n",
        "# !pip -q uninstall -y pyspark\n",
        "# !pip -q install \"pyspark==3.4.3\"\n",
        "import sys\n",
        "import pyspark\n",
        "print(\"python:\", sys.version)\n",
        "print(\"pyspark:\", pyspark.__version__)"
      ],
      "metadata": {
        "id": "DU66BHTGShrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d46GbIK-Q5y8"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import typing as tp\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from implicit.nearest_neighbours import CosineRecommender\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from catboost import CatBoostClassifier, CatBoostRanker\n",
        "try:\n",
        "    from lightgbm import LGBMClassifier, LGBMRanker\n",
        "    LGBM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    warnings.warn(\"lightgbm is not installed. Some parts of the notebook will be skipped.\")\n",
        "    LGBM_AVAILABLE = False\n",
        "from rectools.dataset import Interactions\n",
        "from lightfm import LightFM\n",
        "from rectools import Columns\n",
        "from rectools.dataset import Dataset\n",
        "from rectools.metrics import Precision, Recall, MeanInvUserFreq, Serendipity,MAP,NDCG,HitRate\n",
        "from rectools.models import (\n",
        "    ImplicitALSWrapperModel,\n",
        "    ImplicitBPRWrapperModel,\n",
        "    LightFMWrapperModel,\n",
        "    PureSVDModel,\n",
        "    ImplicitItemKNNWrapperModel,\n",
        "    EASEModel,\n",
        "    PopularModel)\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "from implicit.bpr import BayesianPersonalizedRanking\n",
        "from implicit.nearest_neighbours import CosineRecommender\n",
        "from rectools.models.base import ExternalIds\n",
        "from rectools.models.ranking import (\n",
        "    CandidateRankingModel,\n",
        "    CandidateGenerator,\n",
        "    Reranker,\n",
        "    CatBoostReranker,\n",
        "    CandidateFeatureCollector,\n",
        "    PerUserNegativeSampler\n",
        ")\n",
        "from rectools.model_selection import cross_validate, TimeRangeSplitter,LastNSplitter,Splitter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_users = '/content/drive/MyDrive/Colab Notebooks/Симбирсофт/recsys/dataset/data_original/users.csv'\n",
        "path_items = '/content/drive/MyDrive/Colab Notebooks/Симбирсофт/recsys/dataset/data_original/items.csv'\n",
        "path_interactions = '/content/drive/MyDrive/Colab Notebooks/Симбирсофт/recsys/dataset/data_original/interactions.csv'\n",
        "\n",
        "\n",
        "users = pd.read_csv(path_users)\n",
        "items = pd.read_csv(path_items)\n",
        "interactions = (\n",
        "    pd.read_csv(path_interactions, parse_dates=[\"last_watch_dt\"])\n",
        "    .rename(columns={\"last_watch_dt\": Columns.Datetime})\n",
        ")\n",
        "interactions = interactions.head(10000)\n",
        "users_clise = users[users['user_id'].isin(interactions['user_id'].unique())]\n",
        "interactions[\"weight\"] = 1\n",
        "dataset = Dataset.construct(interactions)\n",
        "RANDOM_STATE = 32\n",
        "# dataset"
      ],
      "metadata": {
        "id": "yYk0XhrxWWxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from replay.preprocessing.history_based_fp import LogStatFeaturesProcessor\n",
        "from replay.utils.session_handler import get_spark_session, State\n",
        "from replay.experimental.preprocessing.data_preparator import DataPreparator, Indexer\n",
        "spark = State().session\n",
        "spark.sparkContext.setLogLevel('ERROR')\n",
        "dp = DataPreparator()\n",
        "log = dp.transform(data=interactions,\n",
        "                  columns_mapping={\n",
        "                      \"user_id\": \"user_id\",\n",
        "                      \"item_id\":  \"item_id\",\n",
        "                      \"relevance\": \"watched_pct\",\n",
        "                      \"timestamp\": \"datetime\"\n",
        "                  })\n",
        "\n",
        "log.show(2)"
      ],
      "metadata": {
        "id": "oHkq9DDdxfp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = Indexer(user_col='user_id', item_col='item_id')\n",
        "indexer.fit(users=log.select('user_id'),\n",
        "            items=log.select('item_id'))\n",
        "log = indexer.transform(df=log)\n",
        "log.show(2)"
      ],
      "metadata": {
        "id": "AFzFWc23-CU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from replay.preprocessing.history_based_fp import LogStatFeaturesProcessor\n",
        "lf = LogStatFeaturesProcessor()\n",
        "lf.fit(log)\n",
        "log_trsfrm = lf.transform(log)\n",
        "log_trsfrm.show(1, vertical=True)"
      ],
      "metadata": {
        "id": "Kv5xCnVg-CXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_trsfrm = lf.transform(log)"
      ],
      "metadata": {
        "id": "9bOcftl_P7BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_trsfrm.show(1, vertical=True)"
      ],
      "metadata": {
        "id": "l63c31Rl-CZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_pd = log_trsfrm.toPandas()\n",
        "rename_map = {\n",
        "    \"user_idx\": \"user_id\",\n",
        "    \"item_idx\": \"item_id\",\n",
        "    \"timestamp\": \"datetime\",\n",
        "    \"relevance\": \"watched_pct\"}\n",
        "\n",
        "log_pd = log_pd.rename(columns=rename_map)\n",
        "# log_pd  = Interactions.construct(log_pd)\n",
        "log_pd"
      ],
      "metadata": {
        "id": "_MtRA6q7iq6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_pd[['item_id', 'user_id', 'datetime', 'total_dur', 'watched_pct', 'weight',\n",
        "#        'u_log_num_interact', 'u_log_interact_days_count',\n",
        "#        'u_min_interact_date', 'u_max_interact_date', 'u_std', 'u_mean',\n",
        "#        'u_quantile_05', 'u_quantile_5', 'u_quantile_95',\n",
        "#        'u_history_length_days', 'u_last_interaction_gap_days', 'abnormality',\n",
        "#        'abnormalityCR', 'u_mean_i_log_num_interact', 'i_log_num_interact',\n",
        "#        'i_log_interact_days_count', 'i_min_interact_date',\n",
        "#        'i_max_interact_date', 'i_std', 'i_mean', 'i_quantile_05',\n",
        "#        'i_quantile_5', 'i_quantile_95', 'i_history_length_days',\n",
        "#        'i_last_interaction_gap_days', 'i_mean_u_log_num_interact',\n",
        "#        'na_u_log_features', 'na_i_log_features', 'u_i_log_num_interact_diff',\n",
        "#        'i_u_log_num_interact_diff']]"
      ],
      "metadata": {
        "id": "3z7N2M9dZEwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare first stage models. They will be used to generate candidates for reranking\n",
        "first_stage = [\n",
        "    # CandidateGenerator(PopularModel(), num_candidates=100, keep_ranks=True, keep_scores=True),\n",
        "    # CandidateGenerator(\n",
        "    #     ImplicitItemKNNWrapperModel(CosineRecommender()),\n",
        "    #     num_candidates=100,\n",
        "    #     keep_ranks=True,\n",
        "    #     keep_scores=True\n",
        "    # ),\n",
        "    CandidateGenerator(\n",
        "        ImplicitALSWrapperModel(\n",
        "          AlternatingLeastSquares(\n",
        "            factors=10,  # latent embeddings size\n",
        "            regularization=0.1,\n",
        "            iterations=10,\n",
        "            alpha=50,  # confidence multiplier for non-zero entries in interactions\n",
        "            random_state=RANDOM_STATE)),\n",
        "    num_candidates=100, keep_ranks=True, keep_scores=True),\n",
        "    CandidateGenerator(\n",
        "        LightFMWrapperModel(\n",
        "            LightFM(no_components=10,\n",
        "                    loss=\"bpr\",\n",
        "                    random_state=RANDOM_STATE)),\n",
        "    num_candidates=100, keep_ranks=True, keep_scores=True\n",
        ")\n",
        "]"
      ],
      "metadata": {
        "id": "PKNU4EvuaVfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomFeatureCollector(CandidateFeatureCollector):\n",
        "\n",
        "    def __init__(self, log_df) -> None:\n",
        "        self.log_df = log_df\n",
        "\n",
        "\n",
        "    # # your any helper functions for working with loaded data\n",
        "    # def _encode_cat_cols(self, df: pd.DataFrame, cols: tp.List[str]) -> pd.DataFrame:\n",
        "    #     for col in cols:\n",
        "    #         df[col] = df[col].astype(\"category\").cat.codes.astype(\"category\")\n",
        "    #     return df\n",
        "\n",
        "    # def _get_user_features(\n",
        "    #     self, users: ExternalIds, dataset: Dataset, fold_info: tp.Optional[tp.Dict[str, tp.Any]]\n",
        "    # ) -> pd.DataFrame:\n",
        "    #     columns = self.user_cat_cols.copy()\n",
        "    #     print(users)\n",
        "    #     columns.append(Columns.User)\n",
        "\n",
        "    #     # user_features = pd.read_csv(self.user_features_path)[columns]\n",
        "    #     user_features = users_clise[columns]\n",
        "\n",
        "\n",
        "    #     users_without_features = pd.DataFrame(\n",
        "    #         np.setdiff1d(dataset.user_id_map.external_ids, user_features[Columns.User].unique()),\n",
        "    #         columns=[Columns.User]\n",
        "    #     )\n",
        "    #     # print(users_without_features)\n",
        "    #     # print(user_features)\n",
        "    #     # print(fold_info)\n",
        "    #     user_features = pd.concat([user_features, users_without_features], axis=0)\n",
        "    #     print(user_features)\n",
        "    #     user_features = self._encode_cat_cols(user_features, self.user_cat_cols)\n",
        "    #     print(user_features)\n",
        "    #     print(fold_info)\n",
        "    #     print(user_features[user_features[Columns.User].isin(users)])\n",
        "    #     return user_features[user_features[Columns.User].isin(users)]\n",
        "    def _get_user_item_features(\n",
        "        self, useritem: pd.DataFrame, dataset: Dataset, fold_info: tp.Optional[tp.Dict[str, tp.Any]]\n",
        "    ) -> pd.DataFrame:\n",
        "        # print(useritem['user_id'])\n",
        "        # print(useritem['user_id'].values)\n",
        "        # print(self.log_df['user_id'])\n",
        "        # print(self.log_df[self.log_df['user_id'].isin(useritem['user_id'].unique())])\n",
        "        # print(useritem['user_id'].values)\n",
        "        # print(self.log_df[self.log_df['user_id'].isin([684368,1014363,424980])])\n",
        "        return self.log_df[self.log_df['user_id'].isin(useritem['user_id'].values)]\n",
        ""
      ],
      "metadata": {
        "id": "LO8CtVoFieZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To transfer CatBoostRanker we use CatBoostReranker\n",
        "splitter = TimeRangeSplitter(\"1D\", n_splits=1)\n",
        "\n",
        "# Categorical features are definitely transferred to the pool_kwargs\n",
        "pool_kwargs = {\n",
        "    \"cat_features\": [\"age\", \"income\", \"sex\"]\n",
        "}\n",
        "\n",
        "two_stage_catboost_ranker = CandidateRankingModel(\n",
        "    candidate_generators=first_stage,\n",
        "    splitter=splitter,\n",
        "    reranker=CatBoostReranker(CatBoostRanker(verbose=False, random_state=RANDOM_STATE)),#pool_kwargs=pool_kwargs\n",
        "    sampler=PerUserNegativeSampler(n_negatives=3, random_state=RANDOM_STATE), # pass sampler to fix random_state\n",
        "    # feature_collector=CandidateFeatureCollector(),\n",
        "    feature_collector=CustomFeatureCollector(log_df=log_pd),\n",
        "    verbose=1\n",
        ")\n",
        "candidates = two_stage_catboost_ranker.get_train_with_targets_for_reranker(dataset) #log_pd dataset\n",
        "candidates.head(5)"
      ],
      "metadata": {
        "id": "VDMM1UNWXY5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "candi = two_stage_catboost_ranker.split_to_history_dataset_and_train_targets(dataset,splitter)\n",
        "candi"
      ],
      "metadata": {
        "id": "cd5JDuXLVuvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions[interactions['user_id']==1014363]"
      ],
      "metadata": {
        "id": "q3SgkTfFl_CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions[interactions['datetime']=='2021-08-22']"
      ],
      "metadata": {
        "id": "alsZjBtxXZGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions[interactions['user_id'].isin([966733,424980,761394,1014363,684368])] #966733  1014363"
      ],
      "metadata": {
        "id": "1WyzKl7CXZIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "items[items['item_id']==913] #931 1267"
      ],
      "metadata": {
        "id": "H3CE-eEAcxd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users[users['user_id']==684368] #684368 1014363"
      ],
      "metadata": {
        "id": "-axbdQRCa8yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D-UiARsra809"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TyzLKTtyXZLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lVbFPmexXZN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import typing as tp\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from rectools import Columns\n",
        "from rectools.dataset import Dataset\n",
        "from rectools.models.ranking import CandidateFeatureCollector  # если у тебя импорт другой — оставь как было\n",
        "\n",
        "ExternalIds = tp.Iterable[tp.Any]\n",
        "\n",
        "\n",
        "class CustomFeatureCollector(CandidateFeatureCollector):\n",
        "    def __init__(\n",
        "        self,\n",
        "        user_features_path: Path,\n",
        "        user_cat_cols: tp.List[str],\n",
        "        pair_features: pd.DataFrame,  # <-- добавили\n",
        "    ) -> None:\n",
        "        self.user_features_path = user_features_path\n",
        "        self.user_cat_cols = user_cat_cols\n",
        "        self.pair_features = pair_features\n",
        "\n",
        "    def _encode_cat_cols(self, df: pd.DataFrame, cols: tp.List[str]) -> pd.DataFrame:\n",
        "        for col in cols:\n",
        "            df[col] = df[col].astype(\"category\").cat.codes.astype(\"category\")\n",
        "        return df\n",
        "\n",
        "    def _get_user_features(\n",
        "        self, users: ExternalIds, dataset: Dataset, fold_info: tp.Optional[tp.Dict[str, tp.Any]]\n",
        "    ) -> pd.DataFrame:\n",
        "        columns = self.user_cat_cols.copy()\n",
        "        columns.append(Columns.User)\n",
        "        user_features = pd.read_csv(self.user_features_path)[columns]\n",
        "\n",
        "        users_without_features = pd.DataFrame(\n",
        "            np.setdiff1d(dataset.user_id_map.external_ids, user_features[Columns.User].unique()),\n",
        "            columns=[Columns.User],\n",
        "        )\n",
        "        user_features = pd.concat([user_features, users_without_features], axis=0)\n",
        "        user_features = self._encode_cat_cols(user_features, self.user_cat_cols)\n",
        "\n",
        "        return user_features[user_features[Columns.User].isin(users)]\n",
        "\n",
        "    def _get_pair_features(\n",
        "        self, pairs: pd.DataFrame\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        pairs: DataFrame со столбцами [user_id, item_id] (то есть [Columns.User, Columns.Item])\n",
        "        возвращает pair-features только для нужных пар\n",
        "        \"\"\"\n",
        "        # Оставим только те пары, которые нужны для текущих candidates\n",
        "        pf = pairs.merge(self.pair_features, on=[Columns.User, Columns.Item], how=\"left\")\n",
        "\n",
        "        # Заполним NaN нулями по всем добавленным фичам\n",
        "        added_cols = [c for c in self.pair_features.columns if c not in (Columns.User, Columns.Item)]\n",
        "        pf[added_cols] = pf[added_cols].fillna(0)\n",
        "\n",
        "        return pf\n",
        "\n",
        "    def collect(  # <-- если у тебя метод называется иначе, скажи/пришли ошибку - переименуем\n",
        "        self,\n",
        "        dataset: Dataset,\n",
        "        candidates: pd.DataFrame,\n",
        "        fold_info: tp.Optional[tp.Dict[str, tp.Any]] = None,\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        candidates обычно содержит как минимум Columns.User и Columns.Item (+ score/target/etc)\n",
        "        Возвращаем датафрейм с признаками для reranker (CatBoost).\n",
        "        \"\"\"\n",
        "        # 1) user-features\n",
        "        users = candidates[Columns.User].unique()\n",
        "        uf = self._get_user_features(users=users, dataset=dataset, fold_info=fold_info)\n",
        "\n",
        "        # 2) pair-features (на конкретные пары candidates)\n",
        "        pairs = candidates[[Columns.User, Columns.Item]].drop_duplicates()\n",
        "        pf = self._get_pair_features(pairs)\n",
        "\n",
        "        # 3) join: candidates + user_features + pair_features\n",
        "        out = (\n",
        "            candidates\n",
        "            .merge(uf, on=Columns.User, how=\"left\")\n",
        "            .merge(pf, on=[Columns.User, Columns.Item], how=\"left\")\n",
        "        )\n",
        "\n",
        "        # user фичи для отсутствующих пользователей\n",
        "        out[self.user_cat_cols] = out[self.user_cat_cols].fillna(-1)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "wztEQQPJZ-a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # To transfer CatBoostRanker we use CatBoostReranker\n",
        "# splitter = TimeRangeSplitter(\"7D\", n_splits=1)\n",
        "\n",
        "# # Categorical features are definitely transferred to the pool_kwargs\n",
        "# pool_kwargs = {\n",
        "#     \"cat_features\": [\"age\", \"income\", \"sex\"]\n",
        "# }\n",
        "\n",
        "# two_stage_catboost_ranker = CandidateRankingModel(\n",
        "#     candidate_generators=first_stage,\n",
        "#     splitter=splitter,\n",
        "#     reranker=CatBoostReranker(CatBoostRanker(verbose=False, random_state=RANDOM_STATE), pool_kwargs=pool_kwargs),\n",
        "#     sampler=PerUserNegativeSampler(n_negatives=3, random_state=RANDOM_STATE), # pass sampler to fix random_state\n",
        "#     # feature_collector=CandidateFeatureCollector(),\n",
        "#     feature_collector=CustomFeatureCollector(user_features_path=path_users, user_cat_cols=[\"age\", \"income\", \"sex\"] ),\n",
        "\n",
        "# )"
      ],
      "metadata": {
        "id": "2jOSxTKahrpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pool_kwargs как у тебя\n",
        "pool_kwargs = {\"cat_features\": [\"age\", \"income\", \"sex\"]}\n",
        "\n",
        "\n",
        "two_stage_catboost_ranker = CandidateRankingModel(\n",
        "    candidate_generators=first_stage,\n",
        "    splitter=splitter,\n",
        "    reranker=CatBoostReranker(\n",
        "        CatBoostRanker(verbose=False, random_state=RANDOM_STATE),\n",
        "        pool_kwargs=pool_kwargs\n",
        "    ),\n",
        "    sampler=PerUserNegativeSampler(n_negatives=3, random_state=RANDOM_STATE),\n",
        "    feature_collector=CustomFeatureCollector(\n",
        "        user_features_path=path_users,\n",
        "        user_cat_cols=[\"age\", \"income\", \"sex\"],\n",
        "        pair_features=log_pd[['item_id', 'user_id', 'datetime', 'total_dur', 'watched_pct', 'weight',\n",
        "       'u_log_num_interact', 'u_log_interact_days_count',\n",
        "       'u_min_interact_date', 'u_max_interact_date', 'u_std', 'u_mean',\n",
        "       'u_quantile_05', 'u_quantile_5', 'u_quantile_95',\n",
        "       'u_history_length_days', 'u_last_interaction_gap_days', 'abnormality',\n",
        "       'abnormalityCR', 'u_mean_i_log_num_interact', 'i_log_num_interact',\n",
        "       'i_log_interact_days_count', 'i_min_interact_date',\n",
        "       'i_max_interact_date', 'i_std', 'i_mean', 'i_quantile_05',\n",
        "       'i_quantile_5', 'i_quantile_95', 'i_history_length_days',\n",
        "       'i_last_interaction_gap_days', 'i_mean_u_log_num_interact',\n",
        "       'na_u_log_features', 'na_i_log_features', 'u_i_log_num_interact_diff',\n",
        "       'i_u_log_num_interact_diff']],  # <-- добавили\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "3OgLp1ABaCej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rename_map = {\n",
        "    \"user_idx\": \"user_id\",\n",
        "    \"item_idx\": \"item_id\",\n",
        "    \"timestamp\": \"datetime\",\n",
        "    \"relevance\": \"watched_pct\"}\n",
        "\n",
        "log_pd = log_pd.rename(columns=rename_map)\n",
        "log_pd.head()\n",
        "dataset = Dataset.construct(log_pd)"
      ],
      "metadata": {
        "id": "sVn8eutbSzyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.construct(log_pd)"
      ],
      "metadata": {
        "id": "JYPqjoZuTvEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = two_stage_catboost_ranker.get_train_with_targets_for_reranker(dataset)"
      ],
      "metadata": {
        "id": "NgfQV2Wqr5a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates.head(10)"
      ],
      "metadata": {
        "id": "ATXDzCTYsJ2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "two_stage_catboost_ranker.fit(dataset)"
      ],
      "metadata": {
        "id": "8zoL7FsaxaL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_users = dataset.user_id_map.external_ids\n",
        "users_to_recommend = all_users[:100]\n",
        "\n",
        "reco_catboost_ranker = two_stage_catboost_ranker.recommend(\n",
        "    users=users_to_recommend,\n",
        "    dataset=dataset,\n",
        "    k=10,\n",
        "    filter_viewed=True\n",
        ")\n",
        "reco_catboost_ranker.head(5)"
      ],
      "metadata": {
        "id": "vfCXY0LwuIxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take few models to compare\n",
        "models = {\n",
        "    \"popular\": PopularModel(),\n",
        "    \"cosine_knn\": ImplicitItemKNNWrapperModel(CosineRecommender()),\n",
        "    'iALS':ImplicitALSWrapperModel(\n",
        "          AlternatingLeastSquares(\n",
        "            factors=10,  # latent embeddings size\n",
        "            regularization=0.1,\n",
        "            iterations=10,\n",
        "            alpha=50,  # confidence multiplier for non-zero entries in interactions\n",
        "            random_state=RANDOM_STATE)),\n",
        "    'LightFM':LightFMWrapperModel(\n",
        "            LightFM(no_components=10,\n",
        "                    loss=\"bpr\",\n",
        "                    random_state=RANDOM_STATE)),\n",
        "    \"two_stage_catboost_ranker\": two_stage_catboost_ranker,\n",
        "}\n",
        "\n",
        "# We will calculate several classic (precision@k and recall@k) and \"beyond accuracy\" metrics\n",
        "metrics = {\n",
        "    \"prec@10\": Precision(k=10),\n",
        "    \"recall@10\": Recall(k=10),\n",
        "    \"novelty@10\": MeanInvUserFreq(k=10),\n",
        "    \"serendipity@10\": Serendipity(k=10),\n",
        "    \"MAP@10\": MAP(k=10),\n",
        "    \"NDCG@10\": NDCG(k=10),\n",
        "    \"HitRate@10\": HitRate(k=10)\n",
        "}\n",
        "\n",
        "K_RECS = 10"
      ],
      "metadata": {
        "id": "mZKMvPCNxqGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = cross_validate(\n",
        "    dataset=dataset,\n",
        "    splitter=splitter,\n",
        "    models=models,\n",
        "    metrics=metrics,\n",
        "    k=K_RECS,\n",
        "    filter_viewed=True,\n",
        ")"
      ],
      "metadata": {
        "id": "XGVagvU-zTNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_results = (\n",
        "    pd.DataFrame(cv_results[\"metrics\"])\n",
        "    .drop(columns=\"i_split\")\n",
        "    .groupby([\"model\"], sort=False)\n",
        "    .agg([\"mean\"])\n",
        ")\n",
        "pivot_results"
      ],
      "metadata": {
        "id": "m4v2muOFzW14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "two_stage_catboost_ranker.get_train_with_targets_for_reranker(dataset)"
      ],
      "metadata": {
        "id": "CmBWQ1rxYeyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}